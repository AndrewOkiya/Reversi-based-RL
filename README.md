# Reversi-based-RL

呐～是吧

我又回来了，依旧是你熟悉的黑白棋，依旧秦时明月的故事背景～

不同的，是你看不到的，用心去感受吧～

啦啦啦～

---

## 进程计划

- [x] 开题报告（2019.02.25 - 2019.03.10）
- [ ] 中期检查（2019.04.20 - 2019.04.30）
- [ ] 作品验收（2019.05.16 - 2019.05.19）
- [ ] 毕业论文（2019.05.20 - 2019.05.29）
- [ ] 毕业答辩（2019.05.30 - 2019.06.06）

---

## To-Do

### Web

#### client

- [x] 游戏逻辑
- [x] AI (Minimax + Alpha–beta pruning)
- [ ] 交互接口

#### server

- [x] 简易的 web 服务器，用来和客户端进行交互



### Python

- [x] Reversi 游戏逻辑，感谢 Eric P. Nichols 的实现，不过里面有点 bug 千千还是去仔细读懂并修复了QAQ，同时也支持了 Python3
- [x] 不同 AI 参与的指挥者 referee
- [ ] Player
    - [x] Human 手动操作
    - [x] 基于随机策略的 AI
    - [x] Botzone 本地 AI 配置（可使用本地 AI 与平台进行对战）
    - [ ] 基于贪心策略的 AI
        - 可贪心使得当前转换棋子数量最大
        - 可贪心使得对方行动力最小
    - [ ] **基于深度强化学习的 AI（最重要）**
        - [ ] MCTS
        - [ ] PyTorch or Tensorflow???
- [ ] Botzone
    - [x] 本地 AI 配置
    - [ ] 可参与天梯对局的 AI

---

## 记录

好难啊啊啊啊啊啊啊，没有进展 QAQ

by im0qianqian 2019.04.04

---

前些天一直在学习如何用强化学习设计 AI，之后想了想后端的游戏逻辑也要实现，于是这两天开工终于差不多完成了，与 Botzone 的本地 AI 配置交互也差不多可以用了，或许也有隐藏的 bug 等待发现，先这样吧~ 接下来继续学习强化学习~

by im0qianqian 2019.04.09