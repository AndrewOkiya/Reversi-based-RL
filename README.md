# Reversi-based-RL

呐～是吧

我又回来了，依旧是你熟悉的黑白棋，依旧秦时明月的故事背景～

不同的，是你看不到的，用心去感受吧～

啦啦啦～

---

## 进程计划

- [x] 开题报告（2019.02.25 - 2019.03.10）
- [x] 中期检查（2019.04.20 - 2019.04.30）
- [ ] 作品验收（2019.05.16 - 2019.05.19）
- [ ] 毕业论文（2019.05.20 - 2019.05.29）
- [ ] 毕业答辩（2019.05.30 - 2019.06.06）

---

## To-Do

### Web

#### client

- [x] 游戏逻辑
- [x] AI (Minimax + Alpha–beta pruning)
- [x] 交互接口

#### server

- [x] 简易的 web 服务器，用来和客户端进行交互



### Python

- [x] Reversi 游戏逻辑，感谢 Eric P. Nichols 的实现，不过里面有点 bug 千千还是去仔细读懂并修复了QAQ，同时也支持了 Python3
- [x] 不同 AI 参与的指挥者 referee
- [ ] Player
    - [x] Human 手动操作
    - [x] 基于随机策略的 AI
    - [x] Botzone 本地 AI 配置（可使用本地 AI 与平台进行对战）
    - [x] 基于贪心策略的 AI
        - 可贪心使得当前转换棋子数量最大
        - 可贪心使得对方行动力最小
    - [ ] **基于深度强化学习的 AI（最重要）**
        - [x] MCTS
        - [ ] PyTorch NNet
- [x] Botzone
    - [x] 本地 AI 配置
    - [x] 可参与天梯对局的 AI

---

## 记录

好难啊啊啊啊啊啊啊，没有进展 QAQ

by im0qianqian 2019.04.04

---

前些天一直在学习如何用强化学习设计 AI，之后想了想后端的游戏逻辑也要实现，于是这两天开工终于差不多完成了，与 Botzone 的本地 AI 配置交互也差不多可以用了，或许也有隐藏的 bug 等待发现，先这样吧~ 接下来继续学习强化学习~

by im0qianqian 2019.04.09

---

看了一下午的 MCTS，似懂非懂的样子，那一堆概率上的公式理解起来虽然不难，但却不知道如何推到这一步的 QAQ，明天继续看，早点手动实现进行下一步。

嗯～今天一拳超人第二季也更新了，坐在机房里看了一集，下午吃完饭回来以后一直不想继续看书，刷了几道 HackerRank AI 部分的题目，还是有点无聊～

旁边的位置，依旧空空的，快点回来好不好，都是千千的错，心情越来越奇怪了，还是虚拟一场 cf 打打吧。

by im0qianqian 2019.04.10

---

感冒了，有点难受，可能是前天淋雨的关系吧！

今天看完了 MCTS，照着步骤应该可以手动实现出来了，但是读了读别的论文发现在 MCTS 中可以结合神经网络进行预测，之前我一直以为这两个是相互独立的关系，唔～再去看看神经网络这块的内容返回来写。

by im0qianqian 2019.04.11

---

完成了 MCTS 部分，接下来便是神经网络了，不清楚这一块实现起来会不会非常麻烦，今天一直很困想睡觉

哦对，林老师中午给千千打电话了，看样子智能所完挂了？？？不过一开始就联系的林老师，也希望能够成为他的学生，保佑千千呀～

by im0qianqian 2019.04.12

---

嗯～这两天没有继续做毕设，一来呢 botzone 上不去了，二来剩下的部分需要深度学习的知识，所以千千想去学学基础啦～就这样～

然后，千千有新导师啦～开心～

by im0qianqian 2019.04.15

---

坐等今晚天梯上分，哒哒……

by im0qianqian 2019.04.17